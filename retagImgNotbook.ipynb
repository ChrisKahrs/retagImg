{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retagImg github repo\n",
    "A notebook to pull in tags from a pretagged dataset that was exported from data labeling in Azure Machine Learning, run a function against each tag (in this case Computer Vision to get dominate color) and finally write the new tags back to a named dataset.\n",
    "\n",
    "#AML #azuremachinelearning #datalabeling #labeldata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Install packages if needed (TODO: create a requirements.txt)\n",
    "import sys\n",
    "!{sys.executable} -m pip install azureml-sdk\n",
    "!{sys.executable} -m pip install azureml-contrib-dataset\n",
    "!{sys.executable} -m pip install azure-storage-blob\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pillow\n",
    "!{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import json, os, shutil\n",
    "import azureml.contrib.dataset\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "from azureml.contrib.dataset import FileHandlingOption,LabeledDatasetTask\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy import ndimage, misc\n",
    "from io import BytesIO\n",
    " \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and read a config file, or just paste your values in directly if you aren't posting anywhere for privacy\n",
    "\"\"\"\n",
    "Create a config.py file in the main notebook directory, it is part of .gitignore and the only thing in it should be as follows: \n",
    "\n",
    "cfg = {\n",
    "    \"subscription_id\" : '<YOUR_SUBSCRIPTION_ID_HERE>',\n",
    "    \"resource_group\" : '<YOUR_RESOURCE_GROUP_HERE>',\n",
    "    \"workspace_name\" : '<YOUR_WORKSPACE_NAME_HERE>',\n",
    "    \"dataset_name\" : '<YOUR_DATASET_NAME_HERE>',\n",
    "    \"output_dataset_name\" : '<YOUR_OUTPUT_DATASET_NAME_HERE>',\n",
    "    \"cognitive_services_endpoint\" : '<YOUR_ENDPOINT_HERE>,\n",
    "    \"cognitive_services_subscription_key\" : '<YOUR_KEY_HERE>',\n",
    "    \"storage_connect_str\": '<YOUR_STORAGE_CONNECTION_STRING_HERE>'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from config import cfg\n",
    "\n",
    "subscription_id = cfg[\"subscription_id\"]\n",
    "resource_group = cfg[\"resource_group\"]\n",
    "workspace_name = cfg[\"workspace_name\"]\n",
    "dataset_name = cfg[\"dataset_name\"]\n",
    "output_dataset_name = cfg[\"output_dataset_name\"]\n",
    "cognitive_services_endpoint = cfg[\"cognitive_services_endpoint\"]\n",
    "cognitive_services_subscription_key = cfg[\"cognitive_services_subscription_key\"]\n",
    "storage_connect_str = cfg[\"storage_connect_str\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup access to AML\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "# to test: df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Lauren Tran code in github (https://github.com/us-ocp-ai/aerial-object-detection)\n",
    "\n",
    "# hack to extract datastore name - no documentation on how to parse StreamInfo - TODO: parse StreamInfo correctly\n",
    "s = str(df.iloc[0].image_url) \n",
    "s = s.split('[')[1].split(']')[0]\n",
    "s = s.replace(\"'\", \"\\\"\") \n",
    "ds = json.loads(s)['datastoreName']\n",
    "\n",
    "# get datastore\n",
    "blob_datastore = Datastore.get(ws, ds)\n",
    "\n",
    "# create temp directory for labeled dataset download\n",
    "tmp_dir = '../tmp'\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "\n",
    "# hack to extract path - no documentation on how to parse StreamInfo - TODO: parse StreamInfo correctly\n",
    "df['path_to_download'] = df['image_url'].apply(lambda x: str(x).split('//')[1].split(\"[\")[0])\n",
    "\n",
    "# to test: df.loc[0, \"path_to_download\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image and zoom.  We zoom here because the 512x512 image may product tags that are smaller than 50x50 \n",
    "# and that is the min needed for Computer Vision to work\n",
    "\n",
    "# download the files (only do once if you are running the cell multiple times comment out)\n",
    "satimg_pd = dataset.to_pandas_dataframe(file_handling_option=FileHandlingOption.DOWNLOAD, target_path='./download/', overwrite_download=True)\n",
    "\n",
    "# for now pull the first row in the df, TODO: iterate the df\n",
    "im = Image.open(satimg_pd.loc[0,'image_url'])\n",
    "\n",
    "print(\"Original Image:\")\n",
    "display(im)\n",
    "\n",
    "print(\"Original Image Size:\")\n",
    "print(im.size)\n",
    "\n",
    "# Convert to an array for zooming\n",
    "ascent = np.asarray(im.convert('RGB'))\n",
    "\n",
    "# Zoom the size (3x), but keep the third dimention (the RGB channel) the same so the colors aren't off\n",
    "result = ndimage.zoom(ascent, (3.0,3.0,1.0), order=1)\n",
    "\n",
    "# Create the image back from the array\n",
    "im_big = Image.fromarray(result)\n",
    "\n",
    "# Calculate the top/left x,y and the bottom/right x,y based on tag from % of the image \n",
    "topx = df['label'][0][0]['topX'] * im_big.size[0]\n",
    "topy = int(df['label'][0][0]['topY'] * im_big.size[1])\n",
    "bottomx = int(df['label'][0][0]['bottomX'] * im_big.size[0])\n",
    "bottomy = int(df['label'][0][0]['bottomY'] * im_big.size[1])\n",
    "\n",
    "# Determine and fix if we don't have enough (50x50) for Computer Vision\n",
    "enoughx = bottomx - topx\n",
    "enoughy = bottomy - topy\n",
    "\n",
    "# expand size for x with more pixels if needed\n",
    "while enoughx < 50:\n",
    "    enoughx = enoughx + 2\n",
    "    topx = topx - 1\n",
    "    bottomx = bottomx + 1\n",
    "\n",
    "# expand size for y with more pixels if needed\n",
    "while enoughy < 50:\n",
    "    enoughy = enoughy + 2\n",
    "    topy = topy - 1\n",
    "    bottomy = bottomy + 1\n",
    "\n",
    "# crop the image with the new xy\n",
    "cropped = im_big.crop((topx, topy, bottomx, bottomy))\n",
    "print(\"Cropped Image:\")\n",
    "display(cropped)\n",
    "\n",
    "# save crop in local directory (TODO: just stream the bits into an array that we can send to ComputerVision without having to save to file)\n",
    "cropped.save('crop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through Computer Vision\n",
    "\n",
    "# Get image (TODO: find a way not to save it but push to computer vision directly)\n",
    "image_path = \"./crop.jpg\"\n",
    "\n",
    "# Read the image into a byte array\n",
    "image_data = open(image_path, \"rb\").read()\n",
    "\n",
    "# Setup for the Cognitive Services call\n",
    "analyze_url = cognitive_services_endpoint + \"vision/v2.1/analyze\"\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': cognitive_services_subscription_key,\n",
    "    'Content-Type': 'application/octet-stream'\n",
    "    }\n",
    "params = {'visualFeatures': 'Color'}\n",
    "\n",
    "# Call the Computer Vision Service\n",
    "response = requests.post(analyze_url, headers=headers, params=params, data=image_data)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Examine the output\n",
    "print(json.dumps(response.json(), indent = 2, separators=(',', ': ')))\n",
    "tags = response.json()\n",
    "\n",
    "# Display the image\n",
    "image = Image.open(BytesIO(image_data))\n",
    "plt.imshow(image)\n",
    "\n",
    "# Get color tag\n",
    "tag = response.json()['color']['dominantColorForeground']\n",
    "print(\"tag: \" + tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_original = df.loc[0,'label'][0]['label']\n",
    "topX_original = df.loc[0,'label'][0]['topX']\n",
    "topY_original = df.loc[0,'label'][0]['topY']\n",
    "bottomX_original = df.loc[0,'label'][0]['bottomX']\n",
    "bottomY_original = df.loc[0,'label'][0]['bottomY']\n",
    "\n",
    "newLabel_dict = {'label': tag + \" \" + label_original, \n",
    "              'topX': topX_original, \n",
    "              'topY': topY_original, \n",
    "              'bottomX':bottomX_original, \n",
    "              'bottomY':bottomY_original}\n",
    "\n",
    "df.loc[0,'label'].append(newLabel_dict)\n",
    "\n",
    "df.loc[0,\"label_confidence\"].append(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra column for downloading\n",
    "df.drop(['path_to_download'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write the new dataset structure to a .jsonl (json lines) file\n",
    "df['image_url'] = df['image_url'].apply(lambda si: '{}://{}/{}'.format(si.handler, si.arguments['datastoreName'], si.resource_identifier))\n",
    "jsonl = df.to_json(orient=\"records\", lines=True)\n",
    "\n",
    "with open('df_colortags.jsonl', 'w+') as f:\n",
    "    f.write(jsonl.replace('\\\\/', '/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO push the file to azure storage so it can be used to create the dataset, manual now\n",
    "\n",
    "\n",
    "# maybe like this?\n",
    "blob_service_client = BlobServiceClient.from_connection_string(storage_connect_str)\n",
    "\n",
    "# Create a blob client using the local file name as the name for the blob\n",
    "blob_client = blob_service_client.get_blob_client(container='satimages', blob='finaldata.json')\n",
    "\n",
    "# Upload the created file\n",
    "with open(\"finaldata.json\", \"rb\") as data:\n",
    "    blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.dataset import LabeledDatasetTask\n",
    "\n",
    "newdataset = Dataset.Labeled.from_json_lines(\n",
    "    blob_datastore.path('./df_colortags2.jsonl'.format(blob_datastore.name)),\n",
    "    LabeledDatasetTask.OBJECT_DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdataset = newdataset.register(workspace=ws,\n",
    "                                 name=\"testing_for_now\", # eventually overwrite \"dangerous\" using the same dataset_name\n",
    "                                 description='added color data',\n",
    "                                 create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_updated = dataset_updated.register(workspace = ws,\n",
    "                                 name = dataset_name,\n",
    "                                 description = 'updated dataset',\n",
    "                                 create_new_version = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write back a file to the same workspace\n",
    "\n",
    "df.to_csv('dataset.csv')\n",
    "blob_datastore.upload(src_dir='../', target_path='../')\n",
    "dataset_updated = Dataset.Tabular.from_delimited_files(blob_datastore.path('../dataset.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"finaldata2.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'][0][0]['topX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show us the actual img snip we get from the coordinates\n",
    "# import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def crop(image, x1, x2, y1, y2):\n",
    "    \"\"\"\n",
    "    Return the cropped image at the x1, x2, y1, y2 coordinates\n",
    "    \"\"\"\n",
    "    if x2 == -1:\n",
    "        x2=image.shape[1]-1\n",
    "    if y2 == -1:\n",
    "        y2=image.shape[0]-1\n",
    "    mask = np.zeros(image.shape)\n",
    "    mask[y1:y2+1, x1:x2+1]=1\n",
    "    m = mask>0\n",
    "    return image[m].reshape((y2+1-y1, x2+1-x1))\n",
    "# img = sp.lena()\n",
    "image_cropped = crop(img, 349,370,202,212)\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax1.imshow(image)\n",
    "ax2.imshow(image_cropped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# If you are using a Jupyter notebook, uncomment the following line.\n",
    "%matplotlib inline\n",
    "\n",
    "# Add your Computer Vision subscription key and endpoint to your environment variables.\n",
    "subscription_key = 'b8397be385f54209a4b250d9a3d7f982'\n",
    "endpoint = \"https://eastus.api.cognitive.microsoft.com/\"\n",
    "\n",
    "analyze_url = endpoint + \"vision/v2.1/analyze\"\n",
    "\n",
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "image_url = \"https://ckahrsmantechstorage.blob.core.windows.net/mantech/veh1.JPG\"\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params = {'visualFeatures': 'Color'}\n",
    "#data = {'url': image_url}\n",
    "#response = requests.post(analyze_url, headers=headers, params=params, json=data)\n",
    "response = requests.post(analyze_url, headers=headers, params=params, data=cropped)\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "# The 'analysis' object contains various fields that describe the image. The most\n",
    "# relevant caption for the image is obtained from the 'description' property.\n",
    "analysis = response.json()\n",
    "print(json.dumps(response.json(), indent = 2, separators=(',', ': ')))\n",
    "\n",
    "\n",
    "# Display the image and overlay it with the caption.\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "# If you are using a Jupyter notebook, uncomment the following line.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# # Add your Computer Vision subscription key and endpoint to your environment variables.\n",
    "# if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
    "#     subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
    "# else:\n",
    "#     print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "#     sys.exit()\n",
    "\n",
    "# if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
    "#     endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
    "\n",
    "# analyze_url = endpoint + \"vision/v3.0/analyze\"\n",
    "\n",
    "# # Set image_path to the local path of an image that you want to analyze.\n",
    "# # Sample images are here, if needed:\n",
    "# # https://github.com/Azure-Samples/cognitive-services-sample-data-files/tree/master/ComputerVision/Images\n",
    "# image_path = \"C:/Documents/ImageToAnalyze.jpg\"\n",
    "image_path = \"./crop.jpg\"\n",
    "\n",
    "\n",
    "# Read the image into a byte array\n",
    "image_data = open(image_path, \"rb\").read()\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "           'Content-Type': 'application/octet-stream'}\n",
    "params = {'visualFeatures': 'Color'}\n",
    "response = requests.post(\n",
    "    analyze_url, headers=headers, params=params, data=image_data)\n",
    "response.raise_for_status()\n",
    "\n",
    "# The 'analysis' object contains various fields that describe the image. The most\n",
    "# relevant caption for the image is obtained from the 'description' property.\n",
    "# analysis = response.json()\n",
    "# print(analysis)\n",
    "print(json.dumps(response.json(), indent = 2, separators=(',', ': ')))\n",
    "# image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "\n",
    "# Display the image and overlay it with the caption.\n",
    "image = Image.open(BytesIO(image_data))\n",
    "plt.imshow(image)\n",
    "# plt.axis(\"off\")\n",
    "# _ = plt.title(image_caption, size=\"x-large\", y=-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(\"DefaultEndpointsProtocol=https;AccountName=ckahrsmantechstorage;AccountKey=FUjBTCqAW6pRv0u+004Hc6eXfh14ly26ZdgK6sVfugEhIMeaUY1fbgDbs6aJp6a77K4ZJrbsdaqLhSEMJTDqTg==;EndpointSuffix=core.windows.net\")\n",
    "all_containers = blob_service_client.list_containers(include_metadata=True)\n",
    "for container in all_containers:\n",
    "    print(container['name'], container['metadata'])\n",
    "    container_client = blob_service_client.get_container_client(container['name'])\n",
    "    generator = container_client.list_blobs()\n",
    "\n",
    "    #code below lists all the blobs in the container and downloads them one after another\n",
    "    for blob in generator:\n",
    "        print(\"   \" + blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(\"DefaultEndpointsProtocol=https;AccountName=ckahrsmantechstorage;AccountKey=FUjBTCqAW6pRv0u+004Hc6eXfh14ly26ZdgK6sVfugEhIMeaUY1fbgDbs6aJp6a77K4ZJrbsdaqLhSEMJTDqTg==;EndpointSuffix=core.windows.net\")\n",
    "\n",
    "# Create a blob client using the local file name as the name for the blob\n",
    "blob_client = blob_service_client.get_blob_client(container='satimages', blob='finaldata.json')\n",
    "\n",
    "# Upload the created file\n",
    "with open(\"finaldata.json\", \"rb\") as data:\n",
    "    blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)  # left side\n",
    "ax2 = fig.add_subplot(122)  # right side\n",
    "ascent = misc.ascent()\n",
    "result = ndimage.zoom(ascent, 2.0)\n",
    "ax1.imshow(ascent)\n",
    "ax2.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(im.convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitretagimgvenvvenv13769d558a8a460186b0712216dcb293",
   "display_name": "Python 3.7.7 64-bit ('retagImg_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}